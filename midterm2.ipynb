{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Sta 663 - Statistical Computing and Computation - Midterm 2\n",
    "-----------\n",
    "Due Wednesday, April 20th by 5:00 pm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary packages\n",
    "import torch\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 1 - `newton()` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Newton function, I began by creating a `hess_check()` function that takes the hessian as an input and ensures the hessian is positive definite. It does this by using the `torch.linalg.cholesky()` function to check for positive definiteness, and in the case this does not occur, it adds a small value to the diagonal and tries again. It will perform 10 iterations before throwing an error. Moving to the `newton()` function, it takes a theta initial guess and a function to optimize, while the rest of the inputs have set values. While in the range of maximum iterations the `newton()` evaluates the function at theta, calculates the gradient, and checks `if max(abs(g)) < (abs(f0)+fscale)*tol`. In the event that this occurs the function has been optimized, `newton()` breaks and a dictionary of outputs including function value at minimum, theta values at minimum, number of iterations to reach minimum, and gradient at minimum is returned. If the function has not been optimized the hessian will be calculated, `hess_check()` will be performed, and a step calculated according to Newton's method will be taken. If the step does not provide improvement it will be halved until it does. However an error will be thrown if any of the following occur: maximum iterations are reached without reaching the optimum, the function evaluated at a theta is not finite, or no improvement to the step occurs after the maximum half steps has occured. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check hessian for positive definiteness\n",
    "def hess_check(hess, max_it = 10):\n",
    "    # set initial values\n",
    "    iteration = 0\n",
    "    positive_def = False\n",
    "    value = 1e-9\n",
    "\n",
    "    while not positive_def:          \n",
    "        try:\n",
    "            # test if hessian is positive definite\n",
    "            torch.linalg.cholesky(hess)\n",
    "            positive_def = True\n",
    "        except:\n",
    "            # count iteration\n",
    "            iteration = iteration + 1\n",
    "            \n",
    "            # raise error if iteration > max_it\n",
    "            if iteration > max_it:\n",
    "                raise RuntimeError(\"Max iterations reached without reaching positive definiteness\")\n",
    "            \n",
    "            # calculate max absolute value of hessian\n",
    "            hess_max = torch.max(torch.abs(hess))\n",
    "            # multiply identity matrix by hess_max and some small value, initially 1e-8\n",
    "            hess_add = torch.eye(hess.shape[0], hess.shape[0]) * value * hess_max * 10\n",
    "            # calculate new hess by adding hess_add\n",
    "            hess = hess + hess_add\n",
    "            \n",
    "    return(hess)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize function using Newton's Method\n",
    "def newton(theta, f, tol = 1e-8, fscale = 1.0, maxit = 100, max_half = 20):\n",
    "    iteration = 0\n",
    "    \n",
    "    for i in range(maxit + 1): \n",
    "        # calculate initial values\n",
    "        f0 = f(theta)\n",
    "        g = torch.autograd.functional.jacobian(f, theta)\n",
    "        \n",
    "        # check if optimization has been reached\n",
    "        if max(abs(g)) < (abs(f0)+fscale)*tol:\n",
    "            break\n",
    "        \n",
    "        # count iteration\n",
    "        iteration = iteration + 1\n",
    "        \n",
    "        # raise error if iteration > maxit\n",
    "        if iteration > maxit:\n",
    "            raise RuntimeError(\"max iterations reached without convergence\")\n",
    "        \n",
    "        # calculate hessian and ensure it is positive definite\n",
    "        hess = torch.autograd.functional.hessian(f, theta)\n",
    "        hess_check(hess)\n",
    "        \n",
    "        # calculate step\n",
    "        step = -torch.matmul(torch.inverse(hess), g)\n",
    "        \n",
    "        half = 0\n",
    "        \n",
    "        for j in range(max_half + 1):\n",
    "            # calculate new theta and evaluate function at new theta\n",
    "            new_theta = theta + step\n",
    "            new_f = f(new_theta)\n",
    "            \n",
    "            # raise error if function is not finite\n",
    "            if torch.isfinite(new_f) is False:\n",
    "                raise ValueError(\"function is not finite\")\n",
    "                \n",
    "            # break if step made improvement\n",
    "            if new_f <= f0:\n",
    "                break\n",
    "                \n",
    "            # count half iteration\n",
    "            half = half + 1\n",
    "            \n",
    "            # raise error if half iterations exceeds max_half\n",
    "            if half > max_half: \n",
    "                raise RuntimeError(\"step fails to reduce the objective after max_half iterations\")\n",
    "            \n",
    "            # divide step by 2 if no improvement occurred\n",
    "            step /= 2\n",
    "        \n",
    "        # set updated theta values\n",
    "        theta = new_theta\n",
    "    \n",
    "    # define output\n",
    "    dict_output = {\"f\" : f(theta), \"theta\" : theta, \"iter\" : iteration, \"grad\" : g}\n",
    "            \n",
    "    return(dict_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Minimization examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Quadratic function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Objective function implementation\n",
    "quad = lambda thetas: thetas[0]**2 - 2*thetas[0] +2*thetas[1]**2 + thetas[1] + 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': tensor(1.8750, dtype=torch.float64),\n",
       " 'theta': tensor([ 1.0000, -0.2500], dtype=torch.float64),\n",
       " 'iter': 1,\n",
       " 'grad': tensor([0., 0.], dtype=torch.float64)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Theta Evaluations\n",
    "theta1 = torch.tensor([0,0], dtype = torch.double)\n",
    "newton(theta = theta1, f = quad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': tensor(1.8750, dtype=torch.float64),\n",
       " 'theta': tensor([ 1.0000, -0.2500], dtype=torch.float64),\n",
       " 'iter': 1,\n",
       " 'grad': tensor([0., 0.], dtype=torch.float64)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Theta Evaluation\n",
    "theta2 = torch.tensor([10,42], dtype = torch.double)\n",
    "newton(theta = theta2, f = quad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': tensor(1.8750, dtype=torch.float64),\n",
       " 'theta': tensor([ 1.0000, -0.2500], dtype=torch.float64),\n",
       " 'iter': 1,\n",
       " 'grad': tensor([0., 0.], dtype=torch.float64)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Theta Evaluation\n",
    "theta3 = torch.tensor([45, 45], dtype = torch.double)\n",
    "newton(theta = theta3, f = quad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Rosenbrock's function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Objective function implementation\n",
    "rose = lambda thetas: 10*(thetas[1] - thetas[0]**2)**2 + (1 - thetas[0])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': tensor(1.3559e-31, dtype=torch.float64),\n",
       " 'theta': tensor([1.0000, 1.0000], dtype=torch.float64),\n",
       " 'iter': 9,\n",
       " 'grad': tensor([-4.6629e-15,  2.2204e-15], dtype=torch.float64)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Theta Evaluation\n",
    "theta1 = torch.tensor([0,0], dtype = torch.double)\n",
    "newton(theta = theta1, f = rose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': tensor(2.3562e-28, dtype=torch.float64),\n",
       " 'theta': tensor([1.0000, 1.0000], dtype=torch.float64),\n",
       " 'iter': 25,\n",
       " 'grad': tensor([ 1.0791e-13, -3.9968e-14], dtype=torch.float64)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Theta Evaluation\n",
    "theta2 = torch.tensor([10,42], dtype = torch.double)\n",
    "newton(theta = theta2, f = rose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': tensor(6.2925e-23, dtype=torch.float64),\n",
       " 'theta': tensor([1.0000, 1.0000], dtype=torch.float64),\n",
       " 'iter': 60,\n",
       " 'grad': tensor([ 1.0157e-10, -4.9396e-11], dtype=torch.float64)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Theta Evaluation\n",
    "theta3 = torch.tensor([45, 45], dtype = torch.double)\n",
    "newton(theta = theta3, f = rose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3. Poisson regression likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\n",
    "   0.11, -0.06, -0.96, -0.48, -0.59, -0.42, -0.15,  1.14, 0.94, \n",
    "  -0.86, -0.08,  1.00, -2.01,  2.17, -0.20,  0.82, -0.13, 0.26, \n",
    "   0.22,  1.05\n",
    "]\n",
    "\n",
    "y = [4, 2, 4, 1, 1, 3, 4, 5, 7, 3, 5, 7, 0, 4, 2, 7, 3, 3, 2, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Objective function implementation\n",
    "def pois_func(thetas):\n",
    "    val = 0\n",
    "    for i in range(20):\n",
    "        l_lam = thetas[0] + thetas[1]*x[i]\n",
    "        l_val = y[i] * l_lam - torch.exp(l_lam) - math.log(math.factorial(y[i]))\n",
    "        val = val + l_val\n",
    "        \n",
    "    return(-val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': tensor(37.8802, dtype=torch.float64),\n",
       " 'theta': tensor([1.2089, 0.4279], dtype=torch.float64),\n",
       " 'iter': 5,\n",
       " 'grad': tensor([6.2172e-15, 3.8788e-15], dtype=torch.float64)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Theta Evaluation\n",
    "theta1 = torch.tensor([1,1], dtype = torch.double)\n",
    "newton(theta = theta1, f = pois_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': tensor(37.8802, dtype=torch.float64),\n",
       " 'theta': tensor([1.2089, 0.4279], dtype=torch.float64),\n",
       " 'iter': 20,\n",
       " 'grad': tensor([9.6183e-08, 1.3595e-07], dtype=torch.float64)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Theta Evaluation\n",
    "theta2 = torch.tensor([10,4.2], dtype = torch.double)\n",
    "newton(theta = theta2, f = pois_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f': tensor(37.8802, dtype=torch.float64),\n",
       " 'theta': tensor([1.2089, 0.4279], dtype=torch.float64),\n",
       " 'iter': 16,\n",
       " 'grad': tensor([9.7700e-15, 9.8740e-15], dtype=torch.float64)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Theta Evaluation\n",
    "theta3 = torch.tensor([4.5, 4.5], dtype = torch.double)\n",
    "newton(theta = theta3, f = pois_func)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
